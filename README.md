# Telecom ELT Pipeline (SQL-based, Containerized)

This project implements a complete **ELT pipeline** for processing and reporting on telecom churn data. It fulfills all requirements of the given problem statement using **SQL**, **PostgreSQL**, **Airflow**, and **Metabase** â€” fully containerized using **Docker Compose**.

---

## ğŸ“Œ Features

- âœ… Ingests raw CSV data (Telecom Churn dataset)
- âœ… Loads into a PostgreSQL staging table
- âœ… Transforms the data using SQL:
  - Fills missing values with defaults
  - Anonymizes PII (`customerID`)
- âœ… Loads transformed data into a `reporting` schema
- âœ… Uses **Airflow** to orchestrate the pipeline on an hourly schedule (configurable)
- âœ… Connects **Metabase** to visualize and report on the cleaned data
- âœ… Runs on any laptop using Docker

---

## ğŸ“ Project Structure

```
telecom-elt-pipeline/
â”œâ”€â”€ data/                      # CSV data files (mounts inside PostgreSQL)
â”œâ”€â”€ sql/                       # SQL scripts for ELT steps
â”‚   â”œâ”€â”€ load_staging.sql
â”‚   â””â”€â”€ transform_clean.sql
â”œâ”€â”€ dags/
â”‚   â””â”€â”€ etl_pipeline.py        # Airflow DAG definition
â”œâ”€â”€ docker-compose.yml         # Containerized setup
â””â”€â”€ README.md
```

---

## ğŸš€ Quickstart (on Mac or Linux)

### 1. Clone this Repository
```bash
git clone https://github.com/YOUR_USERNAME/telecom-elt-pipeline.git
cd telecom-elt-pipeline
```

### 2. Add the Dataset
Download the [Telecom Churn CSV](https://www.kaggle.com/datasets/abdullah0a/telecom-customer-churn-insights-for-analysis) and rename it:
```bash
mv ~/Downloads/telecom_customer_churn.csv ./data/telecom.csv
```

### 3. Start the Pipeline
```bash
docker-compose up --build
```

---

## ğŸŒ Access the Tools

| Tool     | URL                    | Credentials                |
|----------|------------------------|-----------------------------|
| Airflow  | http://localhost:8080  | `airflow / airflow`        |
| Metabase | http://localhost:3000  | First-time setup via browser |

---

## âš™ï¸ How the ELT Works

### ğŸ”„ Airflow DAG (`telecom_elt`)
Runs every hour and executes:
1. `sql/load_staging.sql` â€“ loads CSV into `staging_telecom`
2. `sql/transform_clean.sql` â€“ cleans + anonymizes into `reporting.cleaned_telecom`

### ğŸ§¼ Data Transformations
- `customerID` â†’ anonymized via `MD5()`
- NULL values filled using `COALESCE()`
- Output saved into a separate `reporting` schema

---

## ğŸ“Š Sample Reporting Questions for Metabase

- What percentage of customers churned?
- Churn rate by InternetService type
- Average tenure of churned vs retained customers

---

## ğŸ“¬ Contact

Created by Aditya Prakash â€” for assessment with HG Insights.
